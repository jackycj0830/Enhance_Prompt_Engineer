"""
ä¼˜åŒ–å»ºè®®å¼•æ“æµ‹è¯•è„šæœ¬
"""

import sys
import os
import asyncio
import json
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from app.services.ai_client import get_ai_client
from app.services.prompt_analyzer import get_prompt_analyzer
from app.services.optimization_engine import get_optimization_engine

async def test_optimization_engine():
    """æµ‹è¯•ä¼˜åŒ–å»ºè®®å¼•æ“"""
    print("ğŸ”§ æµ‹è¯•ä¼˜åŒ–å»ºè®®å¼•æ“...")
    
    ai_client = get_ai_client()
    analyzer = get_prompt_analyzer(ai_client)
    optimization_engine = get_optimization_engine(ai_client)
    
    # æµ‹è¯•æç¤ºè¯ï¼ˆæ•…æ„è®¾è®¡å¾—æœ‰æ”¹è¿›ç©ºé—´ï¼‰
    test_prompts = [
        # ç®€å•æ¨¡ç³Šçš„æç¤ºè¯
        "å†™ä¸€ç¯‡æ–‡ç« ",
        
        # ä¸­ç­‰è´¨é‡çš„æç¤ºè¯
        "è¯·å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ï¼Œè¦æ±‚å†…å®¹ä¸°å¯Œï¼Œè¯­è¨€æµç•…ã€‚",
        
        # è¾ƒå¥½ä½†ä»æœ‰æ”¹è¿›ç©ºé—´çš„æç¤ºè¯
        "ä½œä¸ºä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ï¼Œè¯·ä¸ºæˆ‘å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸåº”ç”¨çš„æŠ€æœ¯æ–‡ç« ã€‚æ–‡ç« åº”è¯¥åŒ…å«AIåœ¨è¯Šæ–­ã€æ²»ç–—å’Œè¯ç‰©å‘ç°ä¸­çš„åº”ç”¨ï¼Œé•¿åº¦æ§åˆ¶åœ¨1500å­—å·¦å³ã€‚"
    ]
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\nğŸ“ æµ‹è¯•æç¤ºè¯ {i}: {prompt[:50]}...")
        
        try:
            # 1. å…ˆè¿›è¡Œåˆ†æ
            print("   ğŸ” æ‰§è¡Œåˆ†æ...")
            analysis_result = await analyzer.analyze_prompt(
                text=prompt,
                model=ai_client.get_available_models()[0] if ai_client.get_available_models() else "rule-based",
                use_ai_analysis=len(ai_client.get_available_models()) > 0
            )
            
            print(f"   ğŸ“Š åˆ†æè¯„åˆ†: {analysis_result.metrics.overall_score}/100")
            
            # 2. ç”Ÿæˆä¼˜åŒ–å»ºè®®
            print("   ğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
            user_preferences = {
                "preferred_ai_model": "gpt-3.5-turbo",
                "analysis_depth": "standard",
                "use_case": "æŠ€æœ¯å†™ä½œ"
            }
            
            optimization_result = await optimization_engine.generate_optimization_result(
                analysis=analysis_result,
                user_preferences=user_preferences,
                model=ai_client.get_available_models()[0] if ai_client.get_available_models() else "rule-based",
                use_ai_suggestions=len(ai_client.get_available_models()) > 0
            )
            
            print(f"   âœ… ç”Ÿæˆå»ºè®®æ•°é‡: {len(optimization_result.suggestions)}")
            print(f"   ğŸ“ˆ é¢„æœŸæ”¹è¿›åˆ†æ•°: +{optimization_result.estimated_score_improvement}")
            print(f"   â±ï¸  å¤„ç†æ—¶é—´: {optimization_result.processing_time:.2f}ç§’")
            print(f"   ğŸ¤– ä½¿ç”¨æ¨¡å‹: {optimization_result.model_used}")
            
            # 3. æ˜¾ç¤ºå»ºè®®è¯¦æƒ…
            print("   ğŸ“‹ ä¼˜åŒ–å»ºè®®:")
            for j, suggestion in enumerate(optimization_result.suggestions[:3], 1):
                print(f"      {j}. {suggestion.title} (ä¼˜å…ˆçº§: {suggestion.priority.value}, å½±å“: {suggestion.impact.value})")
                print(f"         æè¿°: {suggestion.description}")
                print(f"         ç½®ä¿¡åº¦: {suggestion.confidence:.2f}")
            
            # 4. æ˜¾ç¤ºä¸ªæ€§åŒ–æ¨è
            if optimization_result.personalized_recommendations:
                print("   ğŸ¯ ä¸ªæ€§åŒ–æ¨è:")
                for rec in optimization_result.personalized_recommendations[:2]:
                    print(f"      â€¢ {rec}")
            
            # 5. æ˜¾ç¤ºæ”¹è¿›è·¯çº¿å›¾
            if optimization_result.improvement_roadmap:
                print("   ğŸ—ºï¸  æ”¹è¿›è·¯çº¿å›¾:")
                for step in optimization_result.improvement_roadmap[:5]:
                    print(f"      {step}")
        
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    return True

async def test_suggestion_types():
    """æµ‹è¯•ä¸åŒç±»å‹çš„å»ºè®®ç”Ÿæˆ"""
    print("\nğŸ¨ æµ‹è¯•å»ºè®®ç±»å‹è¦†ç›–...")
    
    ai_client = get_ai_client()
    analyzer = get_prompt_analyzer(ai_client)
    optimization_engine = get_optimization_engine(ai_client)
    
    # è®¾è®¡ç‰¹å®šé—®é¢˜çš„æç¤ºè¯æ¥æµ‹è¯•ä¸åŒç±»å‹çš„å»ºè®®
    test_cases = [
        {
            "prompt": "åšä¸ªæ€»ç»“",  # æµ‹è¯•æ¸…æ™°åº¦å’Œå…·ä½“æ€§å»ºè®®
            "expected_types": ["clarity", "specificity"]
        },
        {
            "prompt": "ä½ å¥½è¯·å¸®æˆ‘å†™ä¸€ä¸ªå¾ˆé•¿çš„æ–‡ç« å…³äºå¾ˆå¤šä¸åŒçš„ä¸»é¢˜åŒ…æ‹¬ç§‘æŠ€å’Œæ–‡åŒ–è¿˜æœ‰å…¶ä»–çš„ä¸€äº›å†…å®¹è¦æ±‚å†™å¾—å¾ˆå¥½å¾ˆè¯¦ç»†",  # æµ‹è¯•ç»“æ„å»ºè®®
            "expected_types": ["structure", "coherence"]
        },
        {
            "prompt": "å†™æ–‡ç« ",  # æµ‹è¯•ä¸Šä¸‹æ–‡å’Œè§’è‰²å»ºè®®
            "expected_types": ["context", "role"]
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n   æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['prompt']}")
        
        try:
            # åˆ†æ
            analysis_result = await analyzer.analyze_prompt(
                text=test_case["prompt"],
                use_ai_analysis=False  # ä½¿ç”¨è§„åˆ™åˆ†æç¡®ä¿ä¸€è‡´æ€§
            )
            
            # ç”Ÿæˆå»ºè®®
            optimization_result = await optimization_engine.generate_optimization_result(
                analysis=analysis_result,
                use_ai_suggestions=False  # ä½¿ç”¨è§„åˆ™å»ºè®®ç¡®ä¿ä¸€è‡´æ€§
            )
            
            # æ£€æŸ¥å»ºè®®ç±»å‹
            generated_types = [sugg.type.value for sugg in optimization_result.suggestions]
            print(f"   ç”Ÿæˆçš„å»ºè®®ç±»å‹: {generated_types}")
            
            # éªŒè¯æ˜¯å¦åŒ…å«é¢„æœŸç±»å‹
            for expected_type in test_case["expected_types"]:
                if expected_type in generated_types:
                    print(f"   âœ… åŒ…å«é¢„æœŸç±»å‹: {expected_type}")
                else:
                    print(f"   âš ï¸  ç¼ºå°‘é¢„æœŸç±»å‹: {expected_type}")
        
        except Exception as e:
            print(f"   âŒ æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
    
    return True

async def test_personalization():
    """æµ‹è¯•ä¸ªæ€§åŒ–æ¨èåŠŸèƒ½"""
    print("\nğŸ‘¤ æµ‹è¯•ä¸ªæ€§åŒ–æ¨è...")
    
    ai_client = get_ai_client()
    
    if not ai_client.get_available_models():
        print("   âš ï¸  è·³è¿‡ä¸ªæ€§åŒ–æµ‹è¯•ï¼ˆæ— å¯ç”¨AIæ¨¡å‹ï¼‰")
        return True
    
    analyzer = get_prompt_analyzer(ai_client)
    optimization_engine = get_optimization_engine(ai_client)
    
    test_prompt = "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªæ•°æ®"
    
    # ä¸åŒçš„ç”¨æˆ·åå¥½
    user_profiles = [
        {
            "name": "æŠ€æœ¯å†™ä½œè€…",
            "preferences": {
                "preferred_ai_model": "gpt-4",
                "analysis_depth": "deep",
                "use_case": "æŠ€æœ¯æ–‡æ¡£"
            }
        },
        {
            "name": "åˆ›æ„å·¥ä½œè€…",
            "preferences": {
                "preferred_ai_model": "claude-3-sonnet",
                "analysis_depth": "standard",
                "use_case": "åˆ›æ„å†™ä½œ"
            }
        },
        {
            "name": "æ•°æ®åˆ†æå¸ˆ",
            "preferences": {
                "preferred_ai_model": "gpt-3.5-turbo",
                "analysis_depth": "standard",
                "use_case": "æ•°æ®åˆ†æ"
            }
        }
    ]
    
    # åˆ†ææç¤ºè¯
    analysis_result = await analyzer.analyze_prompt(test_prompt)
    
    for profile in user_profiles:
        print(f"\n   ğŸ‘¤ ç”¨æˆ·ç±»å‹: {profile['name']}")
        
        try:
            optimization_result = await optimization_engine.generate_optimization_result(
                analysis=analysis_result,
                user_preferences=profile["preferences"],
                use_ai_suggestions=True
            )
            
            print(f"   ğŸ’¡ ä¸ªæ€§åŒ–æ¨èæ•°é‡: {len(optimization_result.personalized_recommendations)}")
            
            if optimization_result.personalized_recommendations:
                for rec in optimization_result.personalized_recommendations[:2]:
                    print(f"      â€¢ {rec}")
        
        except Exception as e:
            print(f"   âŒ ä¸ªæ€§åŒ–æµ‹è¯•å¤±è´¥: {e}")
    
    return True

async def test_batch_optimization():
    """æµ‹è¯•æ‰¹é‡ä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•æ‰¹é‡ä¼˜åŒ–...")
    
    ai_client = get_ai_client()
    analyzer = get_prompt_analyzer(ai_client)
    optimization_engine = get_optimization_engine(ai_client)
    
    batch_prompts = [
        "å†™ä¸ªæŠ¥å‘Š",
        "ç¿»è¯‘æ–‡æ¡£",
        "åˆ†ææ•°æ®",
        "åˆ›å»ºæ¼”ç¤º"
    ]
    
    try:
        import time
        start_time = time.time()
        
        # æ‰¹é‡åˆ†æå’Œä¼˜åŒ–
        results = []
        for prompt in batch_prompts:
            analysis = await analyzer.analyze_prompt(prompt, use_ai_analysis=False)
            optimization = await optimization_engine.generate_optimization_result(
                analysis, use_ai_suggestions=False
            )
            results.append({
                "prompt": prompt,
                "score": analysis.metrics.overall_score,
                "suggestions": len(optimization.suggestions),
                "improvement": optimization.estimated_score_improvement
            })
        
        total_time = time.time() - start_time
        
        print(f"   âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(batch_prompts)} ä¸ªæç¤ºè¯")
        print(f"   â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   ğŸ“Š å¹³å‡å¤„ç†æ—¶é—´: {total_time/len(batch_prompts):.2f}ç§’/ä¸ª")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        avg_score = sum(r["score"] for r in results) / len(results)
        total_suggestions = sum(r["suggestions"] for r in results)
        avg_improvement = sum(r["improvement"] for r in results) / len(results)
        
        print(f"   ğŸ“ˆ å¹³å‡åˆ†æ•°: {avg_score:.1f}")
        print(f"   ğŸ’¡ æ€»å»ºè®®æ•°: {total_suggestions}")
        print(f"   ğŸ“Š å¹³å‡é¢„æœŸæ”¹è¿›: +{avg_improvement:.1f}")
        
        return True
    
    except Exception as e:
        print(f"   âŒ æ‰¹é‡ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª ä¼˜åŒ–å»ºè®®å¼•æ“æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    # æµ‹è¯•åŸºç¡€ä¼˜åŒ–å¼•æ“
    if not await test_optimization_engine():
        print("\nâŒ åŸºç¡€ä¼˜åŒ–å¼•æ“æµ‹è¯•å¤±è´¥")
        return
    
    # æµ‹è¯•å»ºè®®ç±»å‹è¦†ç›–
    if not await test_suggestion_types():
        print("\nâŒ å»ºè®®ç±»å‹æµ‹è¯•å¤±è´¥")
        return
    
    # æµ‹è¯•ä¸ªæ€§åŒ–æ¨è
    if not await test_personalization():
        print("\nâŒ ä¸ªæ€§åŒ–æ¨èæµ‹è¯•å¤±è´¥")
        return
    
    # æµ‹è¯•æ‰¹é‡ä¼˜åŒ–
    if not await test_batch_optimization():
        print("\nâŒ æ‰¹é‡ä¼˜åŒ–æµ‹è¯•å¤±è´¥")
        return
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¼˜åŒ–å»ºè®®å¼•æ“å·¥ä½œæ­£å¸¸")
    print("\nğŸ’¡ åŠŸèƒ½ç‰¹æ€§:")
    print("   âœ… å¤šç»´åº¦åˆ†æå’Œå»ºè®®ç”Ÿæˆ")
    print("   âœ… æ™ºèƒ½ä¼˜å…ˆçº§æ’åº")
    print("   âœ… ä¸ªæ€§åŒ–æ¨è")
    print("   âœ… æ”¹è¿›è·¯çº¿å›¾ç”Ÿæˆ")
    print("   âœ… æ‰¹é‡å¤„ç†æ”¯æŒ")
    print("   âœ… AIå’Œè§„åˆ™æ··åˆæ¨¡å¼")

if __name__ == "__main__":
    asyncio.run(main())
