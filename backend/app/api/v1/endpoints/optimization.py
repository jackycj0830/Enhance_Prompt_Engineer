"""
ä¼˜åŒ–å»ºè®®APIç«¯ç‚¹
"""

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional
from uuid import UUID
import asyncio

from config.database import get_db
from app.models.user import User, UserPreference
from app.models.prompt import AnalysisResult, OptimizationSuggestion
from app.api.v1.endpoints.auth import get_current_user
from app.services.ai_client import get_ai_client
from app.services.optimization_engine import get_optimization_engine
from app.services.prompt_analyzer import get_prompt_analyzer

router = APIRouter()

async def generate_intelligent_suggestions(
    analysis: AnalysisResult,
    user_preferences: Dict[str, Any],
    model: str = "gpt-3.5-turbo"
) -> Dict[str, Any]:
    """ä½¿ç”¨æ™ºèƒ½å¼•æ“ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    try:
        ai_client = get_ai_client()
        analyzer = get_prompt_analyzer(ai_client)
        optimization_engine = get_optimization_engine(ai_client)

        # é‡æ„åˆ†æç»“æœä¸ºDetailedAnalysisæ ¼å¼
        from app.services.prompt_analyzer import AnalysisMetrics, DetailedAnalysis

        metrics = AnalysisMetrics(
            overall_score=analysis.overall_score,
            semantic_clarity=analysis.semantic_clarity,
            structural_integrity=analysis.structural_integrity,
            logical_coherence=analysis.logical_coherence,
            specificity_score=analysis.analysis_details.get('specificity_score', 70),
            complexity_score=analysis.analysis_details.get('complexity_score', 5.0),
            readability_score=analysis.analysis_details.get('readability_score', 75),
            instruction_clarity=analysis.analysis_details.get('instruction_clarity', 70),
            context_completeness=analysis.analysis_details.get('context_completeness', 70)
        )

        detailed_analysis = DetailedAnalysis(
            metrics=metrics,
            analysis_details=analysis.analysis_details,
            suggestions=analysis.analysis_details.get('suggestions', []),
            strengths=analysis.analysis_details.get('strengths', []),
            weaknesses=analysis.analysis_details.get('weaknesses', []),
            processing_time=analysis.processing_time_ms / 1000.0,
            model_used=analysis.ai_model_used
        )

        # ç”Ÿæˆä¼˜åŒ–ç»“æœ
        optimization_result = await optimization_engine.generate_optimization_result(
            analysis=detailed_analysis,
            user_preferences=user_preferences,
            model=model,
            use_ai_suggestions=True
        )

        return {
            "suggestions": [
                {
                    "id": sugg.id,
                    "type": sugg.type.value,
                    "priority": sugg.priority.value,
                    "impact": sugg.impact.value,
                    "title": sugg.title,
                    "description": sugg.description,
                    "improvement_plan": sugg.improvement_plan,
                    "expected_improvement": sugg.expected_improvement,
                    "examples": sugg.examples,
                    "reasoning": sugg.reasoning,
                    "confidence": sugg.confidence
                }
                for sugg in optimization_result.suggestions
            ],
            "personalized_recommendations": optimization_result.personalized_recommendations,
            "improvement_roadmap": optimization_result.improvement_roadmap,
            "estimated_score_improvement": optimization_result.estimated_score_improvement,
            "processing_time": optimization_result.processing_time,
            "model_used": optimization_result.model_used
        }

    except Exception as e:
        print(f"æ™ºèƒ½å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
        return await fallback_suggestions(analysis)

async def fallback_suggestions(analysis: AnalysisResult) -> Dict[str, Any]:
    """å›é€€å»ºè®®ç”Ÿæˆï¼ˆå½“æ™ºèƒ½å¼•æ“ä¸å¯ç”¨æ—¶ï¼‰"""
    suggestions = []

    # åŸºäºåˆ†æç»“æœç”ŸæˆåŸºç¡€å»ºè®®
    if analysis.semantic_clarity < 80:
        suggestions.append({
            "id": "fallback_1",
            "type": "clarity",
            "priority": 1,
            "impact": "high",
            "title": "æå‡è¯­ä¹‰æ¸…æ™°åº¦",
            "description": "ä½¿ç”¨æ›´å…·ä½“å’Œæ˜ç¡®çš„è¯æ±‡æ¥æé«˜è¯­ä¹‰æ¸…æ™°åº¦",
            "improvement_plan": "å°†æ¨¡ç³Šçš„è¯æ±‡å¦‚'ä¸€äº›'ã€'å¯èƒ½'æ›¿æ¢ä¸ºæ›´ç²¾ç¡®çš„è¡¨è¾¾",
            "expected_improvement": {"semantic_clarity": 15, "overall_score": 8},
            "examples": ["æ¨¡ç³Šï¼š'å†™ä¸€äº›å†…å®¹' â†’ æ¸…æ™°ï¼š'å†™3ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ª100å­—'"],
            "reasoning": "è¯­ä¹‰æ¸…æ™°åº¦ä½ä¼šå¯¼è‡´AIç†è§£åå·®",
            "confidence": 0.8
        })

    if analysis.structural_integrity < 75:
        suggestions.append({
            "id": "fallback_2",
            "type": "structure",
            "priority": 2,
            "impact": "medium",
            "title": "ä¼˜åŒ–ç»“æ„ç»„ç»‡",
            "description": "æ”¹è¿›æç¤ºè¯çš„ç»“æ„ç»„ç»‡ï¼Œä½¿é€»è¾‘æ›´æ¸…æ™°",
            "improvement_plan": "ä½¿ç”¨ç¼–å·åˆ—è¡¨æˆ–åˆ†æ®µæ¥ç»„ç»‡ä¸åŒçš„æŒ‡ä»¤è¦æ±‚",
            "expected_improvement": {"structural_integrity": 20, "overall_score": 10},
            "examples": ["ä½¿ç”¨ï¼š1. èƒŒæ™¯ 2. ä»»åŠ¡ 3. è¦æ±‚ 4. è¾“å‡ºæ ¼å¼"],
            "reasoning": "è‰¯å¥½çš„ç»“æ„æœ‰åŠ©äºAIç†è§£ä»»åŠ¡å±‚æ¬¡",
            "confidence": 0.75
        })

    if analysis.logical_coherence < 85:
        suggestions.append({
            "id": "fallback_3",
            "type": "coherence",
            "priority": 1,
            "impact": "high",
            "title": "å¢å¼ºé€»è¾‘è¿è´¯æ€§",
            "description": "å¢å¼ºæŒ‡ä»¤ä¹‹é—´çš„é€»è¾‘è¿è´¯æ€§",
            "improvement_plan": "æ·»åŠ è¿‡æ¸¡è¯å’Œè¿æ¥è¯æ¥æ”¹å–„æŒ‡ä»¤æµç¨‹",
            "expected_improvement": {"logical_coherence": 15, "overall_score": 8},
            "examples": ["ä½¿ç”¨è¿æ¥è¯ï¼š'é¦–å…ˆ...ç„¶å...æœ€å...'"],
            "reasoning": "é€»è¾‘è¿è´¯æ€§å½±å“AIå¯¹ä»»åŠ¡çš„æ•´ä½“ç†è§£",
            "confidence": 0.7
        })

    return {
        "suggestions": suggestions[:3],
        "personalized_recommendations": [
            "å»ºè®®æ ¹æ®æ‚¨çš„ä½¿ç”¨åœºæ™¯è°ƒæ•´æç¤ºè¯é£æ ¼",
            "è€ƒè™‘æ·»åŠ æ›´å¤šå…·ä½“ç¤ºä¾‹æ¥è¯´æ˜æœŸæœ›è¾“å‡º"
        ],
        "improvement_roadmap": [
            "ğŸ¯ ç«‹å³æ‰§è¡Œï¼šä¿®å¤å…³é”®é—®é¢˜",
            "ğŸ“ˆ çŸ­æœŸä¼˜åŒ–ï¼šå®Œå–„ç»“æ„å’Œæ ¼å¼",
            "ğŸ”§ é•¿æœŸå®Œå–„ï¼šæ·»åŠ é«˜çº§ç‰¹æ€§"
        ],
        "estimated_score_improvement": 15,
        "processing_time": 0.1,
        "model_used": "rule-based"
    }

@router.post("/suggest")
async def generate_suggestions(
    request: dict,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ä¸ºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    analysis_id = request.get("analysis_id")
    if not analysis_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="åˆ†æIDä¸èƒ½ä¸ºç©º"
        )
    
    # éªŒè¯åˆ†æç»“æœå­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    analysis = db.query(AnalysisResult).join(
        AnalysisResult.prompt
    ).filter(
        AnalysisResult.id == analysis_id,
        AnalysisResult.prompt.has(user_id=current_user.id)
    ).first()
    
    if not analysis:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="åˆ†æç»“æœä¸å­˜åœ¨"
        )
    
    # è·å–ç”¨æˆ·åå¥½è®¾ç½®
    user_preferences = {}
    preference = db.query(UserPreference).filter(
        UserPreference.user_id == current_user.id
    ).first()

    if preference:
        user_preferences = {
            "preferred_ai_model": preference.preferred_ai_model,
            "analysis_depth": preference.analysis_depth,
            "use_case": request.get("scenario", "é€šç”¨")
        }

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å»ºè®®
    existing_suggestions = db.query(OptimizationSuggestion).filter(
        OptimizationSuggestion.analysis_id == analysis_id
    ).all()

    if existing_suggestions and not request.get("regenerate", False):
        return {
            "suggestions": [s.to_dict() for s in existing_suggestions],
            "message": "è¿”å›å·²æœ‰çš„ä¼˜åŒ–å»ºè®®",
            "regenerate_available": True
        }

    # ç”Ÿæˆæ–°å»ºè®®
    model = request.get("ai_model", user_preferences.get("preferred_ai_model", "gpt-3.5-turbo"))
    suggestions_result = await generate_intelligent_suggestions(analysis, user_preferences, model)
    
    # æ¸…é™¤æ—§å»ºè®®ï¼ˆå¦‚æœé‡æ–°ç”Ÿæˆï¼‰
    if request.get("regenerate", False):
        db.query(OptimizationSuggestion).filter(
            OptimizationSuggestion.analysis_id == analysis_id
        ).delete()

    # ä¿å­˜æ–°å»ºè®®åˆ°æ•°æ®åº“
    created_suggestions = []
    for sugg_data in suggestions_result["suggestions"]:
        suggestion = OptimizationSuggestion(
            analysis_id=analysis_id,
            suggestion_type=sugg_data["type"],
            priority=sugg_data["priority"],
            description=sugg_data["description"],
            improvement_plan=sugg_data["improvement_plan"],
            expected_impact=sugg_data["impact"],
            is_applied=False
        )
        db.add(suggestion)
        created_suggestions.append(suggestion)

    db.commit()

    for suggestion in created_suggestions:
        db.refresh(suggestion)

    return {
        "suggestions": [s.to_dict() for s in created_suggestions],
        "personalized_recommendations": suggestions_result.get("personalized_recommendations", []),
        "improvement_roadmap": suggestions_result.get("improvement_roadmap", []),
        "estimated_score_improvement": suggestions_result.get("estimated_score_improvement", 0),
        "processing_time": suggestions_result.get("processing_time", 0),
        "model_used": suggestions_result.get("model_used", "unknown"),
        "message": "æˆåŠŸç”Ÿæˆæ™ºèƒ½ä¼˜åŒ–å»ºè®®"
    }

@router.get("/{analysis_id}/suggestions")
async def get_suggestions(
    analysis_id: UUID,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–ç‰¹å®šåˆ†æçš„ä¼˜åŒ–å»ºè®®"""
    # éªŒè¯åˆ†æç»“æœå­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    analysis = db.query(AnalysisResult).join(
        AnalysisResult.prompt
    ).filter(
        AnalysisResult.id == analysis_id,
        AnalysisResult.prompt.has(user_id=current_user.id)
    ).first()
    
    if not analysis:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="åˆ†æç»“æœä¸å­˜åœ¨"
        )
    
    suggestions = db.query(OptimizationSuggestion).filter(
        OptimizationSuggestion.analysis_id == analysis_id
    ).order_by(OptimizationSuggestion.priority).all()
    
    return [s.to_dict() for s in suggestions]

@router.put("/{suggestion_id}/apply")
async def apply_suggestion(
    suggestion_id: UUID,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åº”ç”¨ä¼˜åŒ–å»ºè®®"""
    suggestion = db.query(OptimizationSuggestion).join(
        OptimizationSuggestion.analysis
    ).join(
        AnalysisResult.prompt
    ).filter(
        OptimizationSuggestion.id == suggestion_id,
        AnalysisResult.prompt.has(user_id=current_user.id)
    ).first()
    
    if not suggestion:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ä¼˜åŒ–å»ºè®®ä¸å­˜åœ¨"
        )
    
    suggestion.is_applied = True
    db.commit()
    db.refresh(suggestion)
    
    return {
        "message": "ä¼˜åŒ–å»ºè®®å·²åº”ç”¨",
        "suggestion": suggestion.to_dict()
    }

@router.delete("/{suggestion_id}")
async def delete_suggestion(
    suggestion_id: UUID,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤ä¼˜åŒ–å»ºè®®"""
    suggestion = db.query(OptimizationSuggestion).join(
        OptimizationSuggestion.analysis
    ).join(
        AnalysisResult.prompt
    ).filter(
        OptimizationSuggestion.id == suggestion_id,
        AnalysisResult.prompt.has(user_id=current_user.id)
    ).first()
    
    if not suggestion:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ä¼˜åŒ–å»ºè®®ä¸å­˜åœ¨"
        )
    
    db.delete(suggestion)
    db.commit()
    
    return {"message": "ä¼˜åŒ–å»ºè®®å·²åˆ é™¤"}

@router.post("/apply-suggestions")
async def apply_multiple_suggestions(
    request: Dict[str, Any],
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ‰¹é‡åº”ç”¨ä¼˜åŒ–å»ºè®®"""
    suggestion_ids = request.get("suggestion_ids", [])
    original_prompt = request.get("original_prompt", "")

    if not suggestion_ids:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="è¯·é€‰æ‹©è¦åº”ç”¨çš„å»ºè®®"
        )

    # éªŒè¯å»ºè®®å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    suggestions = []
    for suggestion_id in suggestion_ids:
        suggestion = db.query(OptimizationSuggestion).join(
            OptimizationSuggestion.analysis
        ).join(
            AnalysisResult.prompt
        ).filter(
            OptimizationSuggestion.id == suggestion_id,
            AnalysisResult.prompt.has(user_id=current_user.id)
        ).first()

        if not suggestion:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ä¼˜åŒ–å»ºè®® {suggestion_id} ä¸å­˜åœ¨"
            )
        suggestions.append(suggestion)

    # ç”Ÿæˆä¼˜åŒ–åçš„æç¤ºè¯
    try:
        ai_client = get_ai_client()

        # æ„å»ºä¼˜åŒ–æŒ‡ä»¤
        optimization_instructions = []
        for sugg in suggestions:
            optimization_instructions.append(f"- {sugg.description}: {sugg.improvement_plan}")

        optimization_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¼˜åŒ–å»ºè®®æ”¹è¿›è¿™ä¸ªæç¤ºè¯ï¼š

åŸå§‹æç¤ºè¯ï¼š
{original_prompt}

ä¼˜åŒ–å»ºè®®ï¼š
{chr(10).join(optimization_instructions)}

è¯·è¿”å›ä¼˜åŒ–åçš„æç¤ºè¯ï¼Œä¿æŒåŸæ„çš„åŒæ—¶åº”ç”¨è¿™äº›æ”¹è¿›å»ºè®®ã€‚åªè¿”å›ä¼˜åŒ–åçš„æç¤ºè¯å†…å®¹ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚"""

        if ai_client.get_available_models():
            response = await ai_client.generate_completion(
                prompt=optimization_prompt,
                model="gpt-3.5-turbo",
                temperature=0.3
            )
            optimized_prompt = response.content.strip()
        else:
            optimized_prompt = original_prompt + "\n\n[å»ºè®®ï¼šè¯·æ‰‹åŠ¨åº”ç”¨ä¼˜åŒ–å»ºè®®]"

        # æ ‡è®°å»ºè®®ä¸ºå·²åº”ç”¨
        for suggestion in suggestions:
            suggestion.is_applied = True

        db.commit()

        return {
            "optimized_prompt": optimized_prompt,
            "applied_suggestions": [s.to_dict() for s in suggestions],
            "message": f"æˆåŠŸåº”ç”¨ {len(suggestions)} ä¸ªä¼˜åŒ–å»ºè®®"
        }

    except Exception as e:
        return {
            "optimized_prompt": original_prompt,
            "applied_suggestions": [],
            "error": str(e),
            "message": "è‡ªåŠ¨ä¼˜åŒ–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åº”ç”¨å»ºè®®"
        }

@router.get("/effectiveness/{analysis_id}")
async def get_optimization_effectiveness(
    analysis_id: UUID,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–ä¼˜åŒ–æ•ˆæœç»Ÿè®¡"""
    # éªŒè¯åˆ†æç»“æœå­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    analysis = db.query(AnalysisResult).join(
        AnalysisResult.prompt
    ).filter(
        AnalysisResult.id == analysis_id,
        AnalysisResult.prompt.has(user_id=current_user.id)
    ).first()

    if not analysis:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="åˆ†æç»“æœä¸å­˜åœ¨"
        )

    # è·å–ç›¸å…³å»ºè®®
    suggestions = db.query(OptimizationSuggestion).filter(
        OptimizationSuggestion.analysis_id == analysis_id
    ).all()

    # ç»Ÿè®¡åº”ç”¨æƒ…å†µ
    total_suggestions = len(suggestions)
    applied_suggestions = len([s for s in suggestions if s.is_applied])

    # æŒ‰ç±»å‹ç»Ÿè®¡
    type_stats = {}
    for suggestion in suggestions:
        suggestion_type = suggestion.suggestion_type
        if suggestion_type not in type_stats:
            type_stats[suggestion_type] = {"total": 0, "applied": 0}
        type_stats[suggestion_type]["total"] += 1
        if suggestion.is_applied:
            type_stats[suggestion_type]["applied"] += 1

    # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
    priority_stats = {}
    for suggestion in suggestions:
        priority = suggestion.priority
        if priority not in priority_stats:
            priority_stats[priority] = {"total": 0, "applied": 0}
        priority_stats[priority]["total"] += 1
        if suggestion.is_applied:
            priority_stats[priority]["applied"] += 1

    return {
        "analysis_id": str(analysis_id),
        "original_score": analysis.overall_score,
        "total_suggestions": total_suggestions,
        "applied_suggestions": applied_suggestions,
        "application_rate": round(applied_suggestions / max(total_suggestions, 1) * 100, 1),
        "type_statistics": type_stats,
        "priority_statistics": priority_stats,
        "suggestions_detail": [s.to_dict() for s in suggestions]
    }

@router.get("/user-stats")
async def get_user_optimization_stats(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–ç”¨æˆ·çš„ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
    # è·å–ç”¨æˆ·çš„æ‰€æœ‰åˆ†æç»“æœ
    user_analyses = db.query(AnalysisResult).join(
        AnalysisResult.prompt
    ).filter(
        AnalysisResult.prompt.has(user_id=current_user.id)
    ).all()

    # è·å–æ‰€æœ‰ç›¸å…³çš„ä¼˜åŒ–å»ºè®®
    analysis_ids = [a.id for a in user_analyses]
    all_suggestions = db.query(OptimizationSuggestion).filter(
        OptimizationSuggestion.analysis_id.in_(analysis_ids)
    ).all()

    # ç»Ÿè®¡æ•°æ®
    total_analyses = len(user_analyses)
    total_suggestions = len(all_suggestions)
    applied_suggestions = len([s for s in all_suggestions if s.is_applied])

    # å¹³å‡åˆ†æ•°
    avg_score = np.mean([a.overall_score for a in user_analyses]) if user_analyses else 0

    # æœ€å¸¸è§çš„å»ºè®®ç±»å‹
    type_counts = {}
    for suggestion in all_suggestions:
        suggestion_type = suggestion.suggestion_type
        type_counts[suggestion_type] = type_counts.get(suggestion_type, 0) + 1

    most_common_type = max(type_counts.items(), key=lambda x: x[1])[0] if type_counts else None

    # æ”¹è¿›è¶‹åŠ¿ï¼ˆç®€åŒ–ç‰ˆï¼‰
    recent_analyses = sorted(user_analyses, key=lambda x: x.created_at)[-10:]
    improvement_trend = "stable"
    if len(recent_analyses) >= 2:
        recent_avg = np.mean([a.overall_score for a in recent_analyses[-5:]])
        earlier_avg = np.mean([a.overall_score for a in recent_analyses[:5]])
        if recent_avg > earlier_avg + 5:
            improvement_trend = "improving"
        elif recent_avg < earlier_avg - 5:
            improvement_trend = "declining"

    return {
        "user_id": str(current_user.id),
        "total_analyses": total_analyses,
        "total_suggestions": total_suggestions,
        "applied_suggestions": applied_suggestions,
        "application_rate": round(applied_suggestions / max(total_suggestions, 1) * 100, 1),
        "average_score": round(avg_score, 1),
        "most_common_suggestion_type": most_common_type,
        "improvement_trend": improvement_trend,
        "type_distribution": type_counts
    }
